{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Example syntax:\\nexampleRequest = ndawn_request(startDate='2020-06-23', endDate='2020-06-28', ontology=['Air Pressure', 'Relative Humidity', 'Soil Temperature', 'Wind Direction', 'Wind Speed'], location=['Mavie', 'Ottertail', 'Perham', 'Perley'])\\nndawnDF = exampleRequest.get_data()\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "from io import StringIO\n",
    "\n",
    "class ndawn_request:\n",
    "\n",
    "    def __init__(self, startDate='YYYY-MM-DD', endDate='YYYY-MM-DD', ontology = None, location = None, save = False):\n",
    "\n",
    "        self.start = startDate\n",
    "\n",
    "        self.end = endDate\n",
    "\n",
    "        # List of ontology terms, and their URL codes to build request URL\n",
    "        self.ontology = {\n",
    "            'Air Temperature': ['variable=hdt', 'variable=hdt9'],\n",
    "            'Relative Humidity': ['variable=hdrh', 'variable=hdrh9'],\n",
    "            'Soil Temperature': ['variable=hdbst', 'variable=hdtst'],\n",
    "            'Wind Speed': ['variable=hdws', 'variable=hdmxws', 'variable=hdws10', 'variable=hdmxws10'],\n",
    "            'Wind Direction': ['variable=hdwd', 'variable=hdsdwd', '&variable=hdwd10', 'variable=hdsdwd10'],\n",
    "            'Solar Radiation': ['variable=hdsr'],\n",
    "            'Rainfall': ['variable=hdr'],\n",
    "            'Air Pressure': ['variable=hdbp'],\n",
    "            'Dew Point': ['variable=hddp'],\n",
    "            'Wind Chill': ['variable=hdwc']\n",
    "        }\n",
    "        # Concatenate the ontology keys into a list for exception printout later\n",
    "        ontologiesErrorMessage = '\\n'.join(list(self.ontology.keys()))\n",
    "\n",
    "        # List of stations, and URL codes to build request URL\n",
    "        self.stations = {\n",
    "            'Ada': 78,\n",
    "            'Becker': 118,\n",
    "            'Campbell': 87,\n",
    "            'Clarissa': 124,\n",
    "            'Eldred': 2,\n",
    "            'Fox': 93,\n",
    "            'Greenbush': 70,\n",
    "            'Hubbard': 119,\n",
    "            'Humboldt': 4,\n",
    "            'Kennedy': 82,\n",
    "            'Little Falls': 120,\n",
    "            'Mavie': 71,\n",
    "            'Ottertail': 103,\n",
    "            'Parkers Prairie': 116,\n",
    "            'Perham': 114,\n",
    "            'Perley': 3,\n",
    "            'Pine Point': 115,\n",
    "            'Rice': 121,\n",
    "            'Roseau': 61,\n",
    "            'Sabin': 60,\n",
    "            'Staples': 122,\n",
    "            'Stephen': 5,\n",
    "            'Ulen': 91,\n",
    "            'Wadena': 117,\n",
    "            'Warren': 6,\n",
    "            'Waukon': 92,\n",
    "            'Westport': 123,\n",
    "            'Williams': 95\n",
    "        }\n",
    "        # Concatenate station names into a list for exception printout later\n",
    "        stationsErrorMessage = '\\n'.join(list(self.stations.keys()))\n",
    "\n",
    "        self.save = save\n",
    "\n",
    "        # This checks the start and end dates supplied to make sure they are valid\n",
    "        # Start by converting dates into iso format\n",
    "        startDateCheck = date.fromisoformat(startDate)\n",
    "        endDateCheck = date.fromisoformat(endDate)\n",
    "        # If start date is after end date, raise exception\n",
    "        if startDateCheck > endDateCheck:\n",
    "            raise Exception('End date cannot be before start date')\n",
    "        \n",
    "        # Create empty list to hold URL codes for ontology terms\n",
    "        self.activeMeasures = []\n",
    "        # If user supplies ontology terms\n",
    "        if ontology is not None:\n",
    "            for item in ontology:\n",
    "                # If user-supplied term is not in the dictionary, raise exception\n",
    "                if item not in self.ontology.keys():\n",
    "                    raise Exception('Ontology term [' + str(item) + '] not recognized. Available ontology terms include: ' + '\\n' + ontologiesErrorMessage)\n",
    "                # Otherwise, append URL codes for ontology terms into the list of measurements to be requested\n",
    "                else:\n",
    "                    for code in self.ontology[item]:\n",
    "                        self.activeMeasures.append(code)  \n",
    "        # If user does not supply ontology terms, add all URL codes in dictionary to the list of measurements to be requested    \n",
    "        else:\n",
    "            for key in self.ontology:\n",
    "                for code in self.ontology[key]:\n",
    "                    self.activeMeasures.append(code)\n",
    "\n",
    "        # Create empty list to hold URL codes for stations\n",
    "        self.activeStations = []\n",
    "        # If user supplies station names\n",
    "        if location is not None:\n",
    "            for name in location:\n",
    "                # If user-supplied name is not in the dictionary, raise exception\n",
    "                if name not in self.stations.keys():\n",
    "                    raise Exception('Station [' + str(name) + '] not recognized. Available stations include: ' + '\\n' + stationsErrorMessage)\n",
    "                # Otherwise, append URL codes for stations into the list of stations to be requested\n",
    "                else:\n",
    "                    self.activeStations.append('station=' + str(self.stations[name]))\n",
    "        # If user does not supply station names, add all station URL codes in dictionary to the list of stations to be requested\n",
    "        else:    \n",
    "            for key in self.stations:\n",
    "                self.activeStations.append('station=' + str(self.stations[key]))\n",
    "\n",
    "    def get_data(self):\n",
    "        \n",
    "        # Construct API call for the request\n",
    "        baseURL = 'https://ndawn.ndsu.nodak.edu/table.csv?'\n",
    "        stations = '&'.join(self.activeStations)\n",
    "        measurements = '&'.join(self.activeMeasures)\n",
    "        options = '&ttype=hourly&quick_pick=&begin_date=' + self.start + '&end_date=' + self.end\n",
    "        finalURL = str(baseURL + stations + '&' + measurements + options)\n",
    "        \n",
    "        # Request page\n",
    "        page = requests.get(finalURL)\n",
    "        # If status code not 200, raise exception\n",
    "        if page.status_code != 200:\n",
    "            raise Exception('URL request status not 200. Status code = ' + page.status_code)\n",
    "\n",
    "        print('Request successful')\n",
    "\n",
    "        # Convert csv data to string\n",
    "        content = str(page.content)\n",
    "        # Remove large, unnecessary header\n",
    "        trimContent = content[content.find('Station'):len(content)]\n",
    "        # Replace newline/return with string literal newline\n",
    "        formatContent = trimContent.replace('\\\\r\\\\n', '\\n')\n",
    "        # Convert content to file object\n",
    "        contentFile = StringIO(formatContent)\n",
    "\n",
    "        # Read content into pandas dataframe. Second header row contains units\n",
    "        ndawnData = pd.read_csv(contentFile, header = [0, 1])\n",
    "        \n",
    "        # Concatenate headers to include units\n",
    "        # Assign column list to object\n",
    "        columnHeaders = list(ndawnData.columns)\n",
    "        # List of new headers\n",
    "        newHeaderList = []\n",
    "        # Iterate through column names\n",
    "        for number in range(0, len(columnHeaders)):\n",
    "            # If no unit, keep header unchanged, pass into new list\n",
    "            if 'Unnamed' in columnHeaders[number][1]:\n",
    "                newHeaderList.append(columnHeaders[number][0])\n",
    "            # If unit exists, concatenate header and unit, pass into new list\n",
    "            else:\n",
    "                newHeader = columnHeaders[number][0] + ' (' + columnHeaders[number][1] + ') '\n",
    "                newHeaderList.append(newHeader)\n",
    "        # Assign new column names\n",
    "        ndawnData.columns = newHeaderList\n",
    "\n",
    "        # Create single column for datetime\n",
    "        ndawnData['Date'] = pd.to_datetime(ndawnData[['Year', 'Month', 'Day']])\n",
    "        \n",
    "        # Save to csv if save option selected\n",
    "        if self.save:\n",
    "            ndawnData.to_csv('ndawnData.csv', index=False)\n",
    "\n",
    "        return ndawnData\n",
    "    \n",
    "\"\"\"\n",
    "# Example syntax:\n",
    "exampleRequest = ndawn_request(startDate='2020-06-23', endDate='2020-06-28', ontology=['Air Pressure', 'Relative Humidity', 'Soil Temperature', 'Wind Direction', 'Wind Speed'], location=['Mavie', 'Ottertail', 'Perham', 'Perley'])\n",
    "ndawnDF = exampleRequest.get_data()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "airTempRequest = ndawn_request(save=\"TRUE\", startDate=str(date.today() - datetime.timedelta(30)), endDate=str(date.today()), ontology=['Air Temperature'], location=['Ada','Becker', 'Campbell', 'Clarissa', 'Eldred', 'Fox', 'Greenbush', 'Hubbard', 'Humboldt', 'Kennedy', 'Little Falls', 'Mavie', 'Ottertail', 'Parkers Prairie', 'Perham', 'Perley', 'Pine Point', 'Rice', 'Roseau', 'Sabin', 'Staples', 'Stephen', 'Ulen', 'Wadena', 'Warren', 'Waukon', 'Westport', 'Williams'])\n",
    "ndawnDF = airTempRequest.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D66140B0-0277-45FF-AE18-A787BE3D4AAF:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Latitude (deg)   Longitude (deg)   Avg Air Temp (Degrees F) \n",
      "Station Name                                                                 \n",
      "'                            NaN               NaN                        NaN\n",
      "Ada                    47.321100        -96.513900                  30.737110\n",
      "Becker                 45.344300        -93.850000                  34.274725\n",
      "Campbell               46.064932        -96.370165                  31.880869\n",
      "Clarissa               46.111560        -94.905800                  31.464064\n",
      "Eldred                 47.688000        -96.822000                  30.087563\n",
      "Fox                    48.877738        -95.850160                  27.678771\n",
      "Greenbush              48.704000        -96.325000                  28.285290\n",
      "Hubbard                46.820590        -94.995800                  29.753061\n",
      "Humboldt               48.884000        -97.150000                  27.958778\n",
      "Kennedy                48.636709        -97.041117                  28.708496\n",
      "Little Falls           45.932130        -94.251400                  31.678403\n",
      "Mavie                  48.121000        -95.971000                  28.883515\n",
      "Ottertail              46.426430        -95.573500                  31.165818\n",
      "Parkers Prairie        46.169400        -95.356000                  31.497690\n",
      "Perham                 46.610477        -95.601876                  30.649361\n",
      "Perley                 47.179000        -96.680000                  30.897958\n",
      "Pine Point             47.012860        -95.371700                  28.764515\n",
      "Rice                   45.793830        -94.261800                  32.655900\n",
      "Roseau                 48.685000        -95.734000                  28.183735\n",
      "Sabin                  46.794389        -96.611683                  32.203099\n",
      "Staples                46.387730        -94.808700                  30.793571\n",
      "Stephen                48.456750        -96.853953                  29.405057\n",
      "Ulen                   47.050473        -96.108432                  29.581946\n",
      "Wadena                 46.448300        -95.214200                  30.588447\n",
      "Warren                 48.137000        -96.839000                  28.657219\n",
      "Waukon                 47.325859        -96.132504                  30.352592\n",
      "Westport               45.715080        -95.171800                  32.078071\n",
      "Williams               48.858454        -94.980897                  27.705508\n"
     ]
    }
   ],
   "source": [
    "#calculate average temperatures per station with coordinates\n",
    "\n",
    "df = pd.read_csv(r'ndawnData.csv')\n",
    "\n",
    "meanTemps = df.groupby('Station Name')['Latitude (deg) ', 'Longitude (deg) ', 'Avg Air Temp (Degrees F) '].mean()\n",
    "## print(str(meanTemps))\n",
    "\n",
    "#save as csv\n",
    "meanTemps.to_csv('ndawnMeanTemps.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add average temperatures at stations as feature class\n",
    "\n",
    "with arcpy.EnvManager(scratchWorkspace=r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\", workspace=r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\"):\n",
    "    arcpy.defense.CoordinateTableToPoint(r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\ndawnMeanTemps.csv\", r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\\ndawnMeanTemps_stations\", \"Longitude (deg)\", \"DD_2\", \"Latitude (deg)\", 'GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDW interpolation of mean temps\n",
    "\n",
    "arcpy.ddd.Idw(\"ndawnMeanTemps_stations\", \"Avg_Air_Temp__Degrees_F_\", r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\\IDW_AirTemp\", 0.0132, 2, \"VARIABLE 12\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kriging interpolation of mean temps\n",
    "\n",
    "out_surface_raster = arcpy.sa.Kriging(\"ndawnMeanTemps_stations\", \"Avg_Air_Temp__Degrees_F_\", \"Spherical 0.013200 # # #\", 0.0132, \"VARIABLE 12\", None); out_surface_raster.save(r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\\Kriging_AirTemp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local Polynomial Interpolation of mean temps\n",
    "arcpy.ga.LocalPolynomialInterpolation(\"ndawnMeanTemps_stations\", \"Avg_Air_Temp__Degrees_F_\", None, r\"C:\\Users\\Holly Leaf\\My Drive\\School\\Fall 2021\\GIS 5571 - ArcGIS I\\Labs\\Lab_4\\Lab_4.gdb\\LPI_AirTemp\", 0.0132, 1, \"NBRTYPE=Standard S_MAJOR=1.20984183082956 S_MINOR=1.20984183082956 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\", \"EXPONENTIAL\", None, \"NO_USE_CONDITION_NUMBER\", None, None, \"PREDICTION\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
